{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aperçu et Chargement du Dataset\n",
    "Charger le dataset dans l'environnement Python et se familiariser avec les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aperçu et Chargement du Dataset\n",
    "\n",
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(\"Dataset-Disease-Prediction.csv\")\n",
    "\n",
    "# Afficher les premières lignes du dataset pour se familiariser avec les données\n",
    "df.head()\n",
    "\n",
    "# Afficher les informations du dataset pour comprendre les types de données et les valeurs manquantes\n",
    "df.info()\n",
    "\n",
    "# Afficher les statistiques descriptives du dataset\n",
    "df.describe()\n",
    "\n",
    "# Afficher les colonnes du dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des Données\n",
    "Gérer les valeurs manquantes, normaliser les données et diviser le dataset en données d'entraînement, de test et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement des Données\n",
    "\n",
    "# Gérer les valeurs manquantes en les remplissant avec la valeur la plus fréquente de chaque colonne\n",
    "df = df.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Séparer les caractéristiques (features) et la variable cible (target)\n",
    "X = df.drop('prognosis', axis=1)\n",
    "y = df['prognosis']\n",
    "\n",
    "# Normaliser les données\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Diviser le dataset en données d'entraînement (80%) et de test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Diviser les données d'entraînement en données d'entraînement (80%) et de validation (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection et Validation Croisée des Modèles\n",
    "Effectuer une validation croisée K-Fold sur le dataset d'entraînement pour sélectionner les meilleurs modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection et Validation Croisée des Modèles\n",
    "\n",
    "# Initialiser les modèles de classification\n",
    "svm = SVC()\n",
    "nb = GaussianNB()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Effectuer une validation croisée K-Fold sur le dataset d'entraînement pour chaque modèle\n",
    "k = 5  # Nombre de folds pour la validation croisée\n",
    "\n",
    "# Validation croisée pour SVM\n",
    "svm_scores = cross_val_score(svm, X_train, y_train, cv=k)\n",
    "print(f'SVM Cross-Validation Accuracy: {np.mean(svm_scores):.2f} ± {np.std(svm_scores):.2f}')\n",
    "\n",
    "# Validation croisée pour Naive Bayes\n",
    "nb_scores = cross_val_score(nb, X_train, y_train, cv=k)\n",
    "print(f'Naive Bayes Cross-Validation Accuracy: {np.mean(nb_scores):.2f} ± {np.std(nb_scores):.2f}')\n",
    "\n",
    "# Validation croisée pour Random Forest\n",
    "rf_scores = cross_val_score(rf, X_train, y_train, cv=k)\n",
    "print(f'Random Forest Cross-Validation Accuracy: {np.mean(rf_scores):.2f} ± {np.std(rf_scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement des Classificateurs\n",
    "Entraîner les classificateurs SVM, Naive Bayes et Random Forest, et calculer les métriques de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement des Classificateurs\n",
    "\n",
    "# Entraîner le classificateur SVM\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Calculer les métriques de performance pour SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "print(f'SVM Accuracy: {accuracy_svm:.2f}')\n",
    "print('SVM Classification Report:')\n",
    "print(report_svm)\n",
    "print('SVM Confusion Matrix:')\n",
    "print(conf_matrix_svm)\n",
    "\n",
    "# Entraîner le classificateur Naive Bayes\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculer les métriques de performance pour Naive Bayes\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "report_nb = classification_report(y_test, y_pred_nb)\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "print(f'Naive Bayes Accuracy: {accuracy_nb:.2f}')\n",
    "print('Naive Bayes Classification Report:')\n",
    "print(report_nb)\n",
    "print('Naive Bayes Confusion Matrix:')\n",
    "print(conf_matrix_nb)\n",
    "\n",
    "# Entraîner le classificateur Random Forest\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculer les métriques de performance pour Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Random Forest Accuracy: {accuracy_rf:.2f}')\n",
    "print('Random Forest Classification Report:')\n",
    "print(report_rf)\n",
    "print('Random Forest Confusion Matrix:')\n",
    "print(conf_matrix_rf)\n",
    "\n",
    "# Comparer les métriques de performance entre les classificateurs\n",
    "classifiers = ['SVM', 'Naive Bayes', 'Random Forest']\n",
    "accuracies = [accuracy_svm, accuracy_nb, accuracy_rf]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=classifiers, y=accuracies)\n",
    "plt.title('Comparison of Classifier Accuracies')\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction Utilisant les Données de Validation\n",
    "Utiliser les modèles pour prédire les résultats sur le dataset de validation et combiner les prédictions en utilisant le vote majoritaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction Utilisant les Données de Validation\n",
    "\n",
    "# Prédire les résultats sur le dataset de validation avec chaque classificateur\n",
    "y_val_pred_svm = svm.predict(X_val)\n",
    "y_val_pred_nb = nb.predict(X_val)\n",
    "y_val_pred_rf = rf.predict(X_val)\n",
    "\n",
    "# Combiner les prédictions en utilisant le vote majoritaire\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Empiler les prédictions pour chaque instance\n",
    "predictions = np.vstack((y_val_pred_svm, y_val_pred_nb, y_val_pred_rf)).T\n",
    "\n",
    "# Appliquer le vote majoritaire\n",
    "y_val_pred_ensemble = mode(predictions, axis=1)[0].flatten()\n",
    "\n",
    "# Évaluer le modèle d'ensemble\n",
    "accuracy_ensemble = accuracy_score(y_val, y_val_pred_ensemble)\n",
    "report_ensemble = classification_report(y_val, y_val_pred_ensemble)\n",
    "conf_matrix_ensemble = confusion_matrix(y_val, y_val_pred_ensemble)\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_ensemble:.2f}')\n",
    "print('Ensemble Model Classification Report:')\n",
    "print(report_ensemble)\n",
    "print('Ensemble Model Confusion Matrix:')\n",
    "print(conf_matrix_ensemble)\n",
    "\n",
    "# Visualiser la matrice de confusion pour le modèle d'ensemble\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(conf_matrix_ensemble, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Ensemble Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sortie et Évaluation\n",
    "Évaluer le modèle d'ensemble en comparant les prédictions avec les étiquettes réelles et présenter les résultats avec des matrices de confusion et des graphiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sortie et Évaluation\n",
    "\n",
    "# Évaluer le modèle d'ensemble en comparant les prédictions avec les étiquettes réelles et présenter les résultats avec des matrices de confusion et des graphiques.\n",
    "\n",
    "# Calculer les métriques de performance pour le modèle d'ensemble\n",
    "accuracy_ensemble = accuracy_score(y_val, y_val_pred_ensemble)\n",
    "report_ensemble = classification_report(y_val, y_val_pred_ensemble)\n",
    "conf_matrix_ensemble = confusion_matrix(y_val, y_val_pred_ensemble)\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_ensemble:.2f}')\n",
    "print('Ensemble Model Classification Report:')\n",
    "print(report_ensemble)\n",
    "print('Ensemble Model Confusion Matrix:')\n",
    "print(conf_matrix_ensemble)\n",
    "\n",
    "# Visualiser la matrice de confusion pour le modèle d'ensemble\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(conf_matrix_ensemble, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Ensemble Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Comparer les métriques de performance entre les classificateurs\n",
    "classifiers = ['SVM', 'Naive Bayes', 'Random Forest', 'Ensemble']\n",
    "accuracies = [accuracy_svm, accuracy_nb, accuracy_rf, accuracy_ensemble]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=classifiers, y=accuracies)\n",
    "plt.title('Comparison of Classifier Accuracies')\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
